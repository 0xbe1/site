# 机器学习特征系统

## 没有特征系统的 ML 系统

假设我们的产品是一个短视频 app，我们想上线一个机器学习模型，给用户推荐视频，以提升用户使用 app 的时长。我们应该怎么做？

首先，我们的团队里有小 A 和小 B 两个能手。算法小 A 最喜欢的语言是 Python，熟练使用 Tensorflow/PyTorch/Scikit Learn，还会用 SQL 写复杂查询。服务端小 B 最喜欢的语言是 Go，有丰富的高并发开发经验。小 A 和小 B 一拍即合，由小 A 负责模型训练的全链路，小 B 负责把小 A 训练好的模型上线。

小 A 首先在一台算力强劲的服务器上，打开 Jupyter Notebook，直连数据仓库，手写 SQL 查询，把所需维度过去 30 天的数据全部下载到本地。然后，小 A 快速尝试各种特征生成方法和不同特征的组合，最终选定几十个特征，训练出了在测试数据集上表现良好的模型。小 A 负责任地把代码做了些重构，郑重地把 Notebook 和训练好的模型交到了小 B 手中，「模型弄好了，就差上线了」。

小 B 做的第一件事便是定义推荐服务的 gRPC 接口。「接口接受一个用户 ID，返回 5 个短视频 ID。用户 ID 是不能直接喂给模型的，我得拿到这个用户 ID 对应的特征。」小 B 开始仔细阅读小 A 写的 Python 代码，发现用到的特征至少分为两类：变化频率低的，包括用户年龄、地区等基本信息；变化频率高的，包括用户最近观看的 5 个短视频等行为信息。此外，由于推荐服务对低延迟的要求，这些特征必须缓存起来。于是，小 B 打算申请一个 Redis 集群，并把特征数据注入到 Redis。但是小 B 很快发现，把数据从数据源经过加工注入 Redis 这件事和自己常做的服务端并不太一样，于是小 B 找大数据小 C 帮忙。

小 C 最喜欢的语言是 Java/Scala，熟练使用 Spark/Flink 等计算引擎，经常和 Hive/Kafka 等大数据中间件打交道，有丰富的「使用计算引擎 X 把数据从数据源 Y 导入到数据源 Z」经验。小 C 听完小 B 的描述，

如果涉及实时特征，怎么办？一种做法是，工程团队使用 Java/Scala 重写转换逻辑，部署数据管道，确保批数据和流数据源源不断地经过转换管道，被写入 Redis 存储中。

问题：

- 新特征上线强依赖于工程团队的支持。
- 转换逻辑被不同团队用不同的编程语言实现了两次，正确性很难保证。
- 缺乏特征治理，并不知道特征的具体情况，不同组之间很难共享特征。

抽象是工程师最有力的武器。特征系统是 Michelangelo 在实践中摸索出来的合适抽象，用于解决上述这些问题。

## 服务

服务模块支持特征的大规模批量查询和低延迟点查询。其中，特征的大规模批量查询用于模型训练，低延迟点查询用于在线模型服务。在实践中，服务模块通常对外提供 RPC 接口。

## 存储

存储模块是服务模块的持久化依赖，通常包含离线存储和在线存储。其中，离线存储批量存储特征的历史快照，在线存储只存储特征的最新快照。特征快照包含「主体」和「时刻」这两个关键概念，用于表示某个主体在特定时间节点上的属性值。在实践中，离线存储通常使用 S3/BigQuery/Redshift/Snowflake 之类的数据仓库，在线存储通常使用 DynamoDB/Redis/Cassandra 之类的 K-V 存储。

## 转换

转换模块对接外部数据源，将原始数据经过指定逻辑转换生成特征，注入存储模块。根据实时性的不同，数据源被划分为批数据源和流数据源，因此转换模块也通常分为批转换和流转换。原始数据转换为特征的过程，通常被称为「特征工程」。

## 治理

治理模块是用户与特征系统进行交互的地方。在早期的特征系统中，治理模块只是一个简单的只读仪表盘，用户从中了解到服务、存储和转换各模块的现状。在更成熟的特征系统中，治理模块成为用户定义特征系统行为的控制台。用户可以通过 DSL 的方式定义新特征，生成转换任务，由工作流引擎统一编排，注入存储，最终在服务模块中上线。

## 监控

## 总结
